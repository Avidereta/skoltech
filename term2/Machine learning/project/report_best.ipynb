{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sk_horosh_gus\n",
    "\n",
    "*  Mikhail Usvyatsov\n",
    "*  Ekaterina Yakovleva\n",
    "*  Anastasia Makarova\n",
    "\n",
    "#### Result $0.81245$\n",
    "\n",
    "\n",
    "\n",
    "The winning code consists of simple data cleaning and neural network with tuned parameters\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "* Get rid of symbols except letters\n",
    "* Make letters lower cases\n",
    "* PorterStemmer \n",
    "\n",
    "### Feature processing\n",
    "\n",
    "* Instead of ingredints, single words were used as features\n",
    "* *TD-IDF* and other feature processing tools were not used :)\n",
    "\n",
    "### Structure of Neural Network\n",
    "##### 4 layers: \n",
    "\n",
    "* Input $l_1$\n",
    "\n",
    "* 2 Hidden layers: Dropout $l_2$, Original $l_3$\n",
    "\n",
    "* Output Dropout $l_4$ layer.\n",
    "\n",
    "Links to the Dropout layers are zero out with the probabilities $p_2 = 0.4$ and $p_4 = 0.5$ respectively.\n",
    "\n",
    "Number of units on the Original hidden layer $7000$, activation function - ReLU\n",
    "\n",
    "* Number of epoch $= 400$\n",
    "* Learning rate $= 0.01$\n",
    "* Update momentum (nesterov momentum) $= 0.4$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "train_data = json.load(open('train.json'))\n",
    "test_data = json.load(open('test.json'))\n",
    "\n",
    "def build_dict(train_data):\n",
    "    ingredient_dictionary = dict()\n",
    "    cuisine_dictionary = dict()\n",
    "    inverse_cuisine_dictionary = dict()\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for example in train_data:\n",
    "        if example['cuisine'] not in cuisine_dictionary:\n",
    "            cuisine_dictionary[example['cuisine']] = j\n",
    "            inverse_cuisine_dictionary[j] = example['cuisine']\n",
    "            j += 1\n",
    "        \n",
    "        for ingredient in example['ingredients']:\n",
    "            for word in ingredient.split():\n",
    "                stemmed_word = stemmer.stem(regex.sub('', word.lower()))\n",
    "                        \n",
    "                if stemmed_word not in ingredient_dictionary and len(stemmed_word) > 0:\n",
    "                    ingredient_dictionary[stemmed_word] = i\n",
    "                    i += 1\n",
    "\n",
    "    return ingredient_dictionary, cuisine_dictionary, inverse_cuisine_dictionary\n",
    "        \n",
    "ingredient_dictionary, cuisine_dictionary, inverse_cuisine_dictionary = build_dict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "import numpy as np\n",
    "\n",
    "def build_matrix(examples, ingredient_dictionary, cuisine_dictionary):\n",
    "    matrix = np.zeros((len(examples), len(ingredient_dictionary)), dtype = np.float32)\n",
    "    answers = []\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "    for index, example in enumerate(examples):\n",
    "        for ingredient in example['ingredients']:\n",
    "            for word in ingredient.split():\n",
    "                stemmed_word = stemmer.stem(regex.sub('', word.lower()))\n",
    "                \n",
    "                if len(stemmed_word) > 0 and stemmed_word in ingredient_dictionary:\n",
    "                    matrix[index, ingredient_dictionary[stemmed_word]] = 1\n",
    "        \n",
    "        answers.append(cuisine_dictionary[example['cuisine']])\n",
    "\n",
    "    return matrix, answers\n",
    "\n",
    "train_data_matrix, train_data_labels = build_matrix(train_data, ingredient_dictionary, cuisine_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data_matrix, train_data_labels, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def more_features_matrix(dataset, ingredient_dictionary, cuisine_dictionary):\n",
    "    initial_matrix, _ = build_matrix(dataset, ingredient_dictionary, cuisine_dictionary)\n",
    "    ingredients_len = np.zeros((initial_matrix.shape[0], 1), dtype = np.float32)\n",
    "    \n",
    "    for index, example in enumerate(dataset):\n",
    "        ingredients_len[index] = len(dataset[index]['ingredients'])\n",
    "\n",
    "    return np.hstack((initial_matrix, ingredients_len))\n",
    "\n",
    "train_data_matrixa = more_features_matrix(train_data, ingredient_dictionary, cuisine_dictionary)\n",
    "\n",
    "Xa_train, Xa_val, ya_train, ya_val = train_test_split(train_data_matrixa, train_data_labels, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 765M\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from lasagne.updates import nesterov_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_network(features_number, cuisine_dictionary, max_epochs = 30, update_momentum = 0.4):\n",
    "    network = NeuralNet(\n",
    "        layers = [\n",
    "            ('input', lasagne.layers.InputLayer),\n",
    "            (lasagne.layers.DropoutLayer, {'p' : 0.4}),\n",
    "            (lasagne.layers.DenseLayer, {'num_units' : 7000, 'nonlinearity': lasagne.nonlinearities.rectify}),\n",
    "            (lasagne.layers.DropoutLayer, {'p' : 0.5}),\n",
    "            ('output', lasagne.layers.DenseLayer),\n",
    "        ],\n",
    "        input_shape = (None, features_number),\n",
    "        output_nonlinearity = lasagne.nonlinearities.softmax,\n",
    "        output_num_units = len(cuisine_dictionary),\n",
    "\n",
    "        # optimization method:\n",
    "        update = nesterov_momentum,\n",
    "        update_learning_rate = 0.01,\n",
    "        update_momentum = update_momentum, \n",
    "\n",
    "        regression = False,  # flag to indicate we're dealing with regression problem\n",
    "        max_epochs = max_epochs,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    return network\n",
    "\n",
    "def check_accuracy(network, X_val, y_val):\n",
    "    prediction = network.predict(X_val.astype(np.float32))\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i, answer in enumerate(prediction):\n",
    "        if answer == y_val[i]:\n",
    "            count += 1\n",
    "    \n",
    "    count /= len(y_val)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = build_network(Xa_train.shape[1], cuisine_dictionary, 1600)\n",
    "network.fit(Xa_train, np.array(y_train, dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_accuracy(network, Xa_val, ya_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = build_network(X_train.shape[1], cuisine_dictionary, 173)\n",
    "network.fit(X_train, np.array(y_train, dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_accuracy(network, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network = build_network(train_data_matrix.shape[1], cuisine_dictionary, 173)\n",
    "network.fit(train_data_matrix, np.array(train_data_labels, dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.save_params_to('80_full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test_matrices(data, ingredient_dictionary, cuisine_dictionary):\n",
    "    matrix = np.zeros((len(data), len(ingredient_dictionary)), dtype = np.float32)\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    ids = []\n",
    "\n",
    "    for index, example in enumerate(data):\n",
    "        for ingredient in example['ingredients']:\n",
    "            for word in ingredient.split():\n",
    "                stemmed_word = stemmer.stem(regex.sub('', word.lower()))\n",
    "                \n",
    "                if len(stemmed_word) > 0 and stemmed_word in ingredient_dictionary:\n",
    "                    matrix[index, ingredient_dictionary[stemmed_word]] = 1\n",
    "        \n",
    "        ids.append(example['id'])\n",
    "\n",
    "    return matrix, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_matrix, ids = make_test_matrices(test_data, ingredient_dictionary, cuisine_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answers = network.predict(test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_answers(answers, ids, inverse_cuisine_dictionary):\n",
    "    with open('answers.txt', 'w') as f:\n",
    "        f.write('id,cuisine\\n')\n",
    "        \n",
    "        for index, answer in enumerate(answers):\n",
    "            f.write('{0},{1}\\n'.format(ids[index], inverse_cuisine_dictionary[answer]))\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_answers(answers, ids, inverse_cuisine_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = build_network(train_data_matrix.shape[1], cuisine_dictionary, 173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.load_params_from('82_full.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network.fit(train_data_matrix, np.array(train_data_labels, dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.save_params_to('82_full.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = network.predict_proba(test_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba[:, 9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answers = np.argmax(proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "tf_idf_m = transformer.fit_transform(train_data_matrix, train_data_labels).todense().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(tf_idf_m, train_data_labels, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = build_network(train_data_matrix.shape[1], cuisine_dictionary, 400, 0.3)\n",
    "network.load_params_from('80.93_big_full.dat')\n",
    "network.fit(train_data_matrix, np.array(train_data_labels, dtype = np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = build_network(train_data_matrix.shape[1], cuisine_dictionary, 400, 0.3)\n",
    "network.load_params_from('81.281_big_full.dat')\n",
    "network.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = build_network(X_train.shape[1], cuisine_dictionary, 250, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.load_params_from('81_full.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.save_params_to('80.93_big_full.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = network.get_all_params_values()\n",
    "\n",
    "with open('81_full_another.dat', 'wb') as f:\n",
    "    pickle.dump(params, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(network.get_all_params_values(), open('81_full_another.dat', 'w'), protocol = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
