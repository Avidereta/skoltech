{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk import word_tokenize\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"train.json\")\n",
    "\n",
    "train['ingredients_clean_string'] = [' , '.join(z).strip() for z in traindf['ingredients']]  \n",
    "train['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) \n",
    "                                for line in lists]).strip() for lists in traindf['ingredients']]             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cuisine     id                                        ingredients  \\\n",
      "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
      "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
      "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
      "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
      "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
      "\n",
      "                            ingredients_clean_string  \\\n",
      "0  romaine lettuce , black olives , grape tomatoe...   \n",
      "1  plain flour , ground pepper , salt , tomatoes ...   \n",
      "2  eggs , pepper , salt , mayonaise , cooking oil...   \n",
      "3               water , vegetable oil , wheat , salt   \n",
      "4  black pepper , shallots , cornflour , cayenne ...   \n",
      "\n",
      "                                  ingredients_string  \n",
      "0  romaine lettuce black olives grape tomatoes ga...  \n",
      "1  plain flour ground pepper salt tomato ground b...  \n",
      "2  egg pepper salt mayonaise cooking oil green ch...  \n",
      "3                     water vegetable oil wheat salt  \n",
      "4  black pepper shallot cornflour cayenne pepper ...  \n"
     ]
    }
   ],
   "source": [
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-5036fb23f744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/anastasia/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2148\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 2150\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'type'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_json(\"test.json\") \n",
    "test['ingredients_clean_string'] = [' , '.join(z).strip() for z in testdf['ingredients']]\n",
    "test['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) \n",
    "                                for line in lists]).strip() for lists in testdf['ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_clean_string</th>\n",
       "      <th>ingredients_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>baking powder , eggs , all-purpose flour , rai...</td>\n",
       "      <td>baking powder egg all purpose flour raisin mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>sugar , egg yolks , corn starch , cream of tar...</td>\n",
       "      <td>sugar egg yolks corn starch cream of tartar ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>sausage links , fennel bulb , fronds , olive o...</td>\n",
       "      <td>sausage links fennel bulb frond olive oil cuba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>meat cuts , file powder , smoked sausage , okr...</td>\n",
       "      <td>meat cuts file powder smoked sausage okra shri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>ground black pepper , salt , sausage casings ,...</td>\n",
       "      <td>ground black pepper salt sausage casings leek ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...   \n",
       "\n",
       "                            ingredients_clean_string  \\\n",
       "0  baking powder , eggs , all-purpose flour , rai...   \n",
       "1  sugar , egg yolks , corn starch , cream of tar...   \n",
       "2  sausage links , fennel bulb , fronds , olive o...   \n",
       "3  meat cuts , file powder , smoked sausage , okr...   \n",
       "4  ground black pepper , salt , sausage casings ,...   \n",
       "\n",
       "                                  ingredients_string  \n",
       "0  baking powder egg all purpose flour raisin mil...  \n",
       "1  sugar egg yolks corn starch cream of tartar ba...  \n",
       "2  sausage links fennel bulb frond olive oil cuba...  \n",
       "3  meat cuts file powder smoked sausage okra shri...  \n",
       "4  ground black pepper salt sausage casings leek ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cuisine     id                                        ingredients  \\\n",
      "0        6  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
      "1       16  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
      "2        4  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
      "3        7  22213                [water, vegetable oil, wheat, salt]   \n",
      "4        7  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
      "\n",
      "                            ingredients_clean_string  \\\n",
      "0  romaine lettuce , black olives , grape tomatoe...   \n",
      "1  plain flour , ground pepper , salt , tomatoes ...   \n",
      "2  eggs , pepper , salt , mayonaise , cooking oil...   \n",
      "3               water , vegetable oil , wheat , salt   \n",
      "4  black pepper , shallots , cornflour , cayenne ...   \n",
      "\n",
      "                                  ingredients_string  \n",
      "0  romaine lettuce black olives grape tomatoes ga...  \n",
      "1  plain flour ground pepper salt tomato ground b...  \n",
      "2  egg pepper salt mayonaise cooking oil green ch...  \n",
      "3                     water vegetable oil wheat salt  \n",
      "4  black pepper shallot cornflour cayenne pepper ...  \n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame, Series\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "''' Make cuisine name as numbers'''\n",
    "encoder = LabelEncoder()\n",
    "train['cuisine'] = encoder.fit_transform(train['cuisine'])\n",
    "print train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, Y)\n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-3-62ee5f4ceb5b>, line 188)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-62ee5f4ceb5b>\"\u001b[1;36m, line \u001b[1;32m188\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class ExtractRecipe():\n",
    "    \"\"\" \n",
    "    Class that extracts recipe information from JSON.\n",
    "    \"\"\"\n",
    "    def __init__(self,json):\n",
    "        self.recipe_id = self.set_id(json)\n",
    "        self.cuisine = self.set_cuisine(json)\n",
    "        self.ingredients = self.set_ingredients(json)\n",
    "        self.ingredient_count = len(self.ingredients)\n",
    "    def __str__(self):\n",
    "        return \"ID: %s\\nCuisine: %s\\nIngredients: %s\\nNumber of Ingredients: %s\" % (self.recipe_id, self.cuisine,', '.join(self.ingredients),self.ingredient_count)\n",
    "    def set_id(self,json):\n",
    "        \"\"\"\n",
    "        Method that sets the recipe id.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json['id']\n",
    "        except KeyError:\n",
    "            return '-99'\n",
    "    def set_cuisine(self,json):\n",
    "        \"\"\"\n",
    "        Method that sets the recipe cuisine.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json['cuisine']    \n",
    "        except KeyError:\n",
    "            return ''\n",
    "    def set_ingredients(self,json):\n",
    "        \"\"\"\n",
    "        Method that sets the recipe ingredients.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json['ingredients']\n",
    "        except KeyError:\n",
    "            return []\n",
    "    def clean_ingredient(self,s):\n",
    "    \t\"\"\"\n",
    "    \tMethod that returns a cleaned up version of the entered ingredient.\n",
    "    \t\"\"\"\n",
    "    \tfrom re import sub\n",
    "    \treturn sub('[^A-Za-z0-9]+', ' ', s)\n",
    "    def get_train(self):\n",
    "        \"\"\"\n",
    "        Method that returns a dictionary of data for the training set.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'cuisine':self.cuisine,\n",
    "            'ingredients':', '.join([self.clean_ingredient(x) for x in self.ingredients]),\n",
    "            'ingredient_count':self.ingredient_count\n",
    "        }\n",
    "    def get_predict(self):\n",
    "        \"\"\"\n",
    "        Method that returns a dictionary of data for predicting recipes.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'id':self.recipe_id,\n",
    "            'ingredients':', '.join([self.clean_ingredient(x) for x in self.ingredients]),\n",
    "            'ingredient_count':self.ingredient_count\n",
    "        }   \n",
    "\n",
    "class IngredientModel():\n",
    "\t\"\"\"\n",
    "\tClass that stores an ingredient to cuisine model.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self,model):\n",
    "\t\tself.model = model\n",
    "\tdef predict(self,X):\n",
    "\t\tfrom pandas import Series\n",
    "\t\tfrom operator import add\n",
    "\t\treturn X.ingredients.str.split(',? ').apply(lambda recipe: Series(reduce(add,[self.model.predict_proba([x]) for x in recipe])[0]/len(recipe)))\n",
    "\n",
    "class TextModel():\n",
    "\t\"\"\"\n",
    "\tClass that stores and a simple weighted average of two text-based individual cuisine models.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self,a_model,b_model):\n",
    "\t\tself.a_model = a_model\n",
    "\t\tself.b_model = b_model\n",
    "\t\tself.a_weight = 0.5\n",
    "\t\tself.b_weight = 0.5\n",
    "\tdef set_weights(self,a_weight,b_weight):\n",
    "\t\tself.a_weight = a_weight\n",
    "\t\tself.b_weight = b_weight\n",
    "\tdef blend(self,a_pred,b_pred):\n",
    "\t\treturn a_pred*self.a_weight + b_pred*self.b_weight\n",
    "\tdef predict(self,X):\n",
    "\t\ta_pred = self.a_model.predict_proba(X)[:,1]\n",
    "\t\tb_pred = self.b_model.predict_proba(X)[:,1]\n",
    "\t\treturn self.blend(a_pred,b_pred)\n",
    "\n",
    "class RecipeModel():\n",
    "\t\"\"\"\n",
    "\tClass that stores the models needed to predict the type of cuisine based on a list of ingredients.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self,ingred_model,text_models,recipe_model_a,recipe_model_b,encoder):\n",
    "\t\tself.ingred_model = ingred_model\n",
    "\t\tself.text_models = text_models\n",
    "\t\tself.recipe_model_a = recipe_model_a\n",
    "\t\tself.recipe_model_b = recipe_model_b\n",
    "\t\tself.recipe_weight_a = 0.5\n",
    "\t\tself.recipe_weight_b = 0.5\n",
    "\t\tself.score = 0.0\n",
    "\t\tself.encoder = encoder\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"\\nRecipe Model\\nBlended Accuracy: %0.5f\\nModel A Weight: %0.2f\\nModel B Weight: %0.2f\" % (self.score, self.recipe_weight_a, self.recipe_weight_b)\n",
    "\tdef set_weights(self,pred_a,pred_b,target):\n",
    "\t\tfrom sklearn.metrics import accuracy_score\n",
    "\t\tfor w in zip(range(1,100,1),range(99,0,-1)):\n",
    "\t\t\t\tscore = accuracy_score(target,(pred_a*w[0]/100.0+pred_b*w[1]/100.0).argmax(1))\n",
    "\t\t\t\tif score > self.score:\n",
    "\t\t\t\t\tself.recipe_weight_a = w[0]/100.0\n",
    "\t\t\t\t\tself.recipe_weight_b = w[1]/100.0\n",
    "\t\t\t\t\tself.score = score\n",
    "\tdef predict_kaggle(self,X,prob=False):\n",
    "\t\t# add average ingredient scores for each cuisine\n",
    "\t\tX = X.join(self.ingred_model.predict(X))\n",
    "\t\t# add cuisine based text models\n",
    "\t\tfor v in self.text_models.keys():\n",
    "\t\t\tX['pred_text_'+v] = self.text_models[v].predict(X.ingredients)\n",
    "\t\t# make prediction for recipe model\n",
    "\t\tpred_a = self.recipe_model_a.predict_proba(X)\n",
    "\t\tpred_b = self.recipe_model_b.predict_proba(X)\n",
    "\t\tpred = pred_a*self.recipe_weight_a + pred_b*self.recipe_weight_b\n",
    "\t\tif prob:\n",
    "\t\t\treturn pred\n",
    "\t\telse:\n",
    "\t\t\treturn self.encoder.inverse_transform(pred.argmax(1))\n",
    "\tdef predict(self,json_list,prob=False):\n",
    "\t\t\"\"\"\n",
    "\t\tReturn: The predicted cuisine for the list of recipes. \n",
    "\t\tParams:\n",
    "\t\t\t* json_list (List of Dicts): The list of JSON recipes seeking cuisine predictions. \n",
    "\t\t\t* prob: (Boolean) If the output should be the predicted probability across all cuisines or the best guess label. Defaults to False.\t\n",
    "\t\tDoctest:\n",
    "\t\t>>> json_list = [\n",
    "\t\t...     {\n",
    "\t\t...             'id':1,\n",
    "\t\t...             'ingredients': ['pork, black beans, avocado, orange, cumin, salt, cinnamon']\n",
    "\t\t...     },\n",
    "\t\t...     {\n",
    "\t\t...             'id':2,\n",
    "\t\t...             'ingredients': ['pasta, basil, pine nuts, olive oil, parmesan cheese, garlic']\n",
    "\t\t...     },\n",
    "\t\t...     {\n",
    "\t\t...             'id':3,\n",
    "\t\t...             'ingredients': ['tumeric, red lentils, naan, garam masala, onions, sweet potatoes']\n",
    "\t\t...     }\n",
    "\t\t... ]\n",
    "\t\t>>> recipe_model.predict(json_list)\n",
    "\t\tarray([u'mexican', u'italian', u'indian'], dtype=object)\n",
    "\t\t>>> recipe_model.predict(json_list,prob=True)\n",
    "\t\tarray([[  3.30066887e-03,   1.99567227e-06,   1.69680381e-03,\n",
    "\t\t\t\t  1.05174537e-05,   2.03085874e-05,   3.29112324e-03,\n",
    "\t\t\t\t  1.15989352e-06,   4.94386325e-03,   3.40759867e-06,\n",
    "\t\t\t\t  5.00931910e-03,   1.64480210e-03,   1.65024605e-03,\n",
    "\t\t\t\t  7.54782889e-07,   9.33262747e-01,   5.83895764e-07,\n",
    "\t\t\t\t  3.17332176e-06,   2.34691288e-02,   1.01873500e-02,\n",
    "\t\t\t\t  6.56450009e-03,   4.93754585e-03],\n",
    "\t\t\t   [  1.48577580e-05,   4.19468051e-06,   1.68586413e-03,\n",
    "\t\t\t\t  1.27146558e-05,   8.20049665e-06,   1.16352625e-02,\n",
    "\t\t\t\t  3.69138042e-02,   3.23459014e-05,   1.23802178e-04,\n",
    "\t\t\t\t  5.19810867e-01,   1.16872025e-05,   1.17136206e-04,\n",
    "\t\t\t\t  6.88425371e-06,   4.24320803e-01,   1.23880210e-05,\n",
    "\t\t\t\t  1.07642463e-05,   3.49156883e-03,   1.75572406e-03,\n",
    "\t\t\t\t  2.47755352e-05,   6.35768902e-06],\n",
    "\t\t\t   [  3.28104312e-03,   1.04083038e-05,   1.76803405e-06,\n",
    "\t\t\t\t  1.64068986e-03,   9.84115643e-03,   1.66666236e-03,\n",
    "\t\t\t\t  1.31338270e-02,   6.97641581e-01,   3.29681417e-03,\n",
    "\t\t\t\t  1.31455590e-02,   2.93287824e-06,   7.81646840e-02,\n",
    "\t\t\t\t  3.98645284e-07,   4.43144651e-02,   1.05028641e-01,\n",
    "\t\t\t\t  2.53745611e-06,   2.05663297e-02,   1.67476028e-03,\n",
    "\t\t\t\t  6.58238004e-03,   3.37299002e-06]])\n",
    "\t\t\"\"\"\n",
    "\t\tfrom pandas import DataFrame\n",
    "\t\t# extract features from JSON\n",
    "\t\tX = DataFrame([ExtractRecipe(x).get_predict() for x in json_list])\n",
    "\t\t# add average ingredient scores for each cuisine\n",
    "\t\tX = X.join(self.ingred_model.predict(X))\n",
    "\t\t# add cuisine based text models\n",
    "\t\tfor v in self.text_models.keys():\n",
    "\t\t\tX['pred_text_'+v] = self.text_models[v].predict(X.ingredients)\n",
    "\t\t# make prediction for recipe model\n",
    "\t\tpred_a = self.recipe_model_a.predict_proba(X)\n",
    "\t\tpred_b = self.recipe_model_b.predict_proba(X)\n",
    "        pred = pred_a*self.recipe_weight_a + pred_b*self.recipe_weight_b\n",
    "        if prob:\n",
    "\t\t\treturn pred\n",
    "\t\telse:\n",
    "\t\t\treturn self.encoder.inverse_transform(pred.argmax(1))\n",
    "    \t\n",
    "class VarSelect(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, keys):\n",
    "        self.keys = keys\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        return df[self.keys]\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.wnl = WordNetLemmatizer()\n",
    "\tdef __call__(self, doc):\n",
    "\t\treturn [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "def stripString(s):\n",
    "\treturn ', '.join([''.join(y.lower() for y in x if y.isalnum()) for x in s.split(',')])\n",
    "\n",
    "def loadTrainSet(dir='../data/train.json'):\n",
    "\t\"\"\"\n",
    "\tRead in JSON to create training set.\n",
    "\t\"\"\"\n",
    "\timport json\n",
    "\tfrom pandas import DataFrame, Series\n",
    "\tfrom sklearn.preprocessing import LabelEncoder\n",
    "\tX = DataFrame([ExtractRecipe(x).get_train() for x in json.load(open(dir,'rb'))])\n",
    "\tencoder = LabelEncoder()\n",
    "\tX['cuisine'] = encoder.fit_transform(X['cuisine'])\n",
    "\treturn X, encoder\n",
    "\n",
    "def loadTestSet(dir='../data/test.json'):\n",
    "\t\"\"\"\n",
    "\tRead in JSON to create test set.\n",
    "\t\"\"\"\n",
    "\timport json\n",
    "\tfrom pandas import DataFrame\n",
    "\treturn DataFrame([ExtractRecipe(x).get_predict() for x in json.load(open(dir,'rb'))])\n",
    "\n",
    "def fitSklearn(X,y,cv,i,model,multi=False):\n",
    "\t\"\"\"\n",
    "\tTrain a sklearn pipeline or model -- wrapper to enable parallel CV.\n",
    "\t\"\"\"\n",
    "\ttr = cv[i][0]\n",
    "\tvl = cv[i][1]\n",
    "\tmodel.fit(X.iloc[tr],y.iloc[tr])\n",
    "\tif multi:\n",
    "\t\treturn  {\"pred\": model.predict_proba(X.iloc[vl]), \"index\":vl}\n",
    "\telse:\n",
    "\t\treturn  {\"pred\": model.predict_proba(X.iloc[vl])[:,1], \"index\":vl}\n",
    "\n",
    "def trainSklearn(model,grid,train,target,cv,refit=True,n_jobs=5,multi=False):\n",
    "\t\"\"\"\n",
    "\tTrain a sklearn pipeline or model using textual data as input.\n",
    "\t\"\"\"\n",
    "\tfrom joblib import Parallel, delayed   \n",
    "\tfrom sklearn.grid_search import ParameterGrid\n",
    "\tfrom numpy import zeros\n",
    "\tif multi:\n",
    "\t\tpred = zeros((train.shape[0],target.unique().shape[0]))\n",
    "\t\tfrom sklearn.metrics import accuracy_score\n",
    "\t\tscore_func = accuracy_score\n",
    "\telse:\n",
    "\t\tfrom sklearn.metrics import roc_auc_score\n",
    "\t\tscore_func = roc_auc_score\n",
    "\t\tpred = zeros(train.shape[0])\n",
    "\tbest_score = 0\n",
    "\tfor g in ParameterGrid(grid):\n",
    "\t\tmodel.set_params(**g)\n",
    "\t\tif len([True for x in g.keys() if x.find('nthread') != -1 ]) > 0:\n",
    "\t\t\tresults = [fitSklearn(train,target,list(cv),i,model,multi) for i in range(cv.n_folds)]\n",
    "\t\telse:\n",
    "\t\t\tresults = Parallel(n_jobs=n_jobs)(delayed(fitSklearn)(train,target,list(cv),i,model,multi) for i in range(cv.n_folds))\n",
    "\t\tif multi:\n",
    "\t\t\tfor i in results:\n",
    "\t\t\t\tpred[i['index'],:] = i['pred']\n",
    "\t\t\tscore = score_func(target,pred.argmax(1))\n",
    "\t\telse:\n",
    "\t\t\tfor i in results:\n",
    "\t\t\t\tpred[i['index']] = i['pred']\n",
    "\t\t\tscore = score_func(target,pred)\n",
    "\t\tif score > best_score:\n",
    "\t\t\tbest_score = score\n",
    "\t\t\tbest_pred = pred.copy()\n",
    "\t\t\tbest_grid = g\n",
    "\tprint \"Best Score: %0.5f\" % best_score \n",
    "\tprint \"Best Grid\", best_grid\n",
    "\tif refit:\n",
    "\t\tmodel.set_params(**best_grid)\n",
    "\t\tmodel.fit(train,target)\n",
    "\treturn best_pred, model\n",
    "\n",
    "def trainText(model_a,modelGrid_a,model_b,modelGrid_b,train,target,cv,refit=True,n_jobs=5):\n",
    "\t\"\"\"\n",
    "\tTrain and blend two univariate text models.\n",
    "\t\"\"\"\n",
    "\tfrom sklearn.metrics import roc_auc_score\n",
    "\tfrom copy import deepcopy\n",
    "\tpred_a, model_a = trainSklearn(deepcopy(model_a),modelGrid_a,train,target,cv,refit=refit,n_jobs=n_jobs)\n",
    "\tpred_b, model_b = trainSklearn(deepcopy(model_b),modelGrid_b,train,target,cv,refit=refit,n_jobs=n_jobs)\n",
    "\tmodels = TextModel(model_a,model_b)\n",
    "\tbest_score = 0\n",
    "\tfor w in zip(range(2,100,2),range(98,0,-2)):\n",
    "\t\tscore = roc_auc_score(target,pred_a*w[0]/100.0+pred_b*w[1]/100.0)\n",
    "\t\tif score > best_score:\n",
    "\t\t\tbest_score = score\n",
    "\t\t\tmodels.set_weights(w[0]/100.0,w[1]/100.0)\n",
    "\tfinal_pred = models.blend(pred_a,pred_b)\n",
    "\tprint \"A Weight:\",models.a_weight\n",
    "\tprint \"B Weight:\", models.b_weight\n",
    "\tprint \"Best Blended Score: %0.5f\" % roc_auc_score(target,final_pred)\n",
    "\treturn final_pred, models\n",
    "\n",
    "def splitIngredients(X):\n",
    "\tfrom pandas import Series\n",
    "\tX2 = X.ingredients.str.split(',? ').apply(lambda x: Series(x)).stack().reset_index(level=1, drop=True)\n",
    "\tX2.name = 'ingredient'\n",
    "\treturn X[['cuisine']].join(X2)\n",
    "\n",
    "def fitIngredients(X,cv,i,model):\n",
    "\t\"\"\"\n",
    "\tTrain a sklearn pipeline or model -- wrapper to enable parallel CV.\n",
    "\t\"\"\"\n",
    "\tfrom operator import add\n",
    "\tfrom pandas import Series\n",
    "\ttr = cv[i][0]\n",
    "\tvl = cv[i][1]\n",
    "\tX2 = splitIngredients(X.iloc[tr])\n",
    "\tmodel.fit(X2.ingredient,X2.cuisine)\n",
    "\treturn  {\"pred\":X.iloc[vl].ingredients.str.split(',? ').apply(lambda recipe:  Series(reduce(add,[model.predict_proba([x]) for x in recipe])[0]/len(recipe))), \"index\":vl}\n",
    "\n",
    "def trainIngredient(model,grid,train,cv,refit=True,n_jobs=5):\n",
    "\tfrom joblib import Parallel, delayed   \n",
    "\tfrom sklearn.grid_search import ParameterGrid\n",
    "\tfrom numpy import zeros\n",
    "\tfrom sklearn.metrics import accuracy_score\n",
    "\tpred = zeros((train.shape[0],train.cuisine.unique().shape[0]))\n",
    "\tbest_score = 0\n",
    "\tfor g in ParameterGrid(grid):\n",
    "\t\tmodel.set_params(**g)\n",
    "\t\tresults = Parallel(n_jobs=n_jobs)(delayed(fitIngredients)(train,list(cv),i,model) for i in range(cv.n_folds))\n",
    "\t\tfor i in results:\n",
    "\t\t\tpred[i['index'],:] = i['pred']\n",
    "\t\tscore = accuracy_score(train.cuisine,pred.argmax(1))\n",
    "\t\tif score > best_score:\n",
    "\t\t\tbest_score = score\n",
    "\t\t\tbest_pred = pred.copy()\n",
    "\t\t\tbest_grid = g\n",
    "\tprint \"Best Score: %0.5f\" % best_score \n",
    "\tprint \"Best Grid\", best_grid\n",
    "\tif refit:\n",
    "\t\tX2 = splitIngredients(train)\n",
    "\t\tmodel.set_params(**best_grid)\n",
    "\t\tmodel.fit(X2.ingredient,X2.cuisine)\n",
    "\treturn best_pred, IngredientModel(model)\n",
    "\t\n",
    "def trainFeatureModel(train,target,model,grid,cv,n_jobs=-1):\n",
    "\tfrom sklearn.grid_search import ParameterGrid\n",
    "\tfrom sklearn.metrics import accuracy_score\n",
    "\tfrom joblib import Parallel, delayed  \n",
    "\tfrom numpy import zeros\n",
    "\tpred = zeros((train.shape[0],target.unique().shape[0]))\n",
    "\tbest_score = 0\n",
    "\tbest_grid = {}\n",
    "\tfor g in ParameterGrid(grid):\n",
    "\t\tmodel.set_params(**g)\n",
    "\t\tif len([True for x in g.keys() if x.find('nthread') != -1 or x.find('n_jobs') != -1 ]) > 0:\n",
    "\t\t\tresults = [fitSklearn(train,target,list(cv),i,model,True) for i in range(cv.n_folds)]\n",
    "\t\telse:\n",
    "\t\t\tresults = Parallel(n_jobs=n_jobs)(delayed(fitSklearn)(train,target,list(cv),i,model,True) for i in range(cv.n_folds))\n",
    "\t\tfor i in results:\n",
    "\t\t\tpred[i['index'],:] = i['pred']\n",
    "\t\tscore = accuracy_score(target,pred.argmax(1))\n",
    "\t\tif score > best_score:\n",
    "\t\t\tbest_score = score\n",
    "\t\t\tbest_pred = pred.copy()\n",
    "\t\t\tbest_grid = g\n",
    "\tprint \"Best Score: %0.5f\" % best_score \n",
    "\tprint \"Best Grid:\", best_grid\n",
    "\tmodel.set_params(**best_grid)\n",
    "\tmodel.fit(train,target)\n",
    "\treturn best_pred, model\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, encoder = loadTrainSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
