{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtractRecipe():\n",
    "    \"\"\" \n",
    "    Extracts recipe information from JSON.\n",
    "    \"\"\"\n",
    "    def __init__(self, json):\n",
    "        self.recipe_id = self.set_id(json)\n",
    "        self.cuisine = self.set_cuisine(json)\n",
    "        self.ingredients = self.set_ingredients(json)\n",
    "        self.ingredient_count = len(self.ingredients)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"ID: %s\\nCuisine: %s\\nIngredients: %s\\nNumber of Ingredients: %s\" % (self.recipe_id,\n",
    "                                    self.cuisine,', '.join(self.ingredients),self.ingredient_count)\n",
    "    def set_id(self,json):\n",
    "        \"\"\"\n",
    "        sets the recipe id.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json['id']\n",
    "        except KeyError:\n",
    "            return '-99'\n",
    "        \n",
    "    def set_cuisine(self,json):\n",
    "        \"\"\"\n",
    "        sets the recipe cuisine.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json['cuisine']    \n",
    "        except KeyError:\n",
    "            return ''\n",
    "        \n",
    "    def set_ingredients(self,json):\n",
    "        \"\"\"\n",
    "        sets the recipe ingredients.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return json['ingredients']\n",
    "        except KeyError:\n",
    "            return []\n",
    "        \n",
    "    def clean_ingredient(self,s):\n",
    "        \"\"\"\n",
    "        returns a cleaned up version of the entered ingredient.\n",
    "        \"\"\"\n",
    "        from re import sub\n",
    "        return sub('[^A-Za-z0-9]+', ' ', s)\n",
    "    \n",
    "    def get_train(self):\n",
    "        \"\"\"\n",
    "        returns a dictionary of data for the training set.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'cuisine':self.cuisine,\n",
    "            'ingredients':', '.join([self.clean_ingredient(x) for x in self.ingredients]),\n",
    "            'ingredient_count':self.ingredient_count\n",
    "        }\n",
    "    \n",
    "    def get_predict(self):\n",
    "        \"\"\"\n",
    "        returns a dictionary of data for predicting recipes.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'id':self.recipe_id,\n",
    "            'ingredients':', '.join([self.clean_ingredient(x) for x in self.ingredients]),\n",
    "            'ingredient_count':self.ingredient_count\n",
    "        }   \n",
    "\n",
    "\n",
    "def loadTrainSet(dir='train.json'):\n",
    "    \"\"\"\n",
    "    Read in JSON to create training set.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pandas import DataFrame, Series\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    X = DataFrame([ExtractRecipe(x).get_train() for x in json.load(open(dir,'rb'))])\n",
    "    encoder = LabelEncoder()\n",
    "    X['cuisine'] = encoder.fit_transform(X['cuisine'])\n",
    "    return X, encoder\n",
    "\n",
    "def loadTestSet(dir='test.json'):\n",
    "    \"\"\"\n",
    "    Read in JSON to create test set.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pandas import DataFrame\n",
    "    return DataFrame([ExtractRecipe(x).get_predict() for x in json.load(open(dir,'rb'))])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df, encoder = loadTrainSet()\n",
    "\n",
    "import nltk\n",
    "\n",
    "def make_unique_ingredients_dict(df):\n",
    "    ingredients = dict()\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    i = 0\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        ingredients_list = row[3].split(', ')\n",
    "\n",
    "        for ingredient in ingredients_list:\n",
    "            words = ingredient.split()\n",
    "            stemmed_words = []\n",
    "\n",
    "            for word in words:\n",
    "                stemmed_words.append(stemmer.stem(word.lower()))\n",
    "\n",
    "            stemmed_ingredient = ' '.join(stemmed_words)\n",
    "\n",
    "            if stemmed_ingredient not in ingredients:\n",
    "                ingredients[stemmed_ingredient] = i\n",
    "                i = i + 1\n",
    "    \n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "def estimate_acc(clf, train_data, train_labels):\n",
    "    scores = cross_validation.cross_val_score(clf, train_data, train_labels, cv = 5)\n",
    "\n",
    "    print('Accuracy on training set: {0} +/- {1}'.format(scores.mean(), scores.std() * 2))\n",
    "    \n",
    "def write_submission(reasult_dict):\n",
    "    \"\"\"File to upload\"\"\"\n",
    "    writer = csv.writer(open('submission.csv', 'wt'))\n",
    "    writer.writerow(['id','cuisine'])\n",
    "    for key, value in result_dict.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "def make_preprocessed_matrix(df, unique_ingridients):\n",
    "    \"\"\"Stemm ingredients in dataframe and put into X\"\"\"\n",
    "    \n",
    "    X = sp.sparse.csr_matrix((train_df.shape[0], 1 + len(unique_ingridients)))\n",
    "    \n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    #print df\n",
    "    for example_number, row in enumerate(df.itertuples()):\n",
    "        #print row[3], '\\n'\n",
    "        #ingridients_list = row[3].split(', ')\n",
    "        \n",
    "        for ingridient in ingridients_list:\n",
    "            words = ingridient.split()\n",
    "            stemmed_words = []\n",
    "\n",
    "            for word in words:\n",
    "                stemmed_words.append(stemmer.stem(word.lower()))\n",
    "            #print stemmed_words\n",
    "            stemmed_ingridient = ' '.join(stemmed_words)\n",
    "            \n",
    "            ingridient_index = unique_ingridients[stemmed_ingridient]\n",
    "            \n",
    "            X[example_number, ingridient_index] = 1\n",
    "            #print X\n",
    "        \n",
    "        X[example_number, len(unique_ingridients) - 1] = row[2]\n",
    "        \n",
    "    return X\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romaine lettuce, black olives, grape tomatoes, garlic, pepper, purple onion, seasoning, garbanzo beans, feta cheese crumbles plain flour, ground pepper, salt, tomatoes, ground black pepper, thyme, eggs, green tomatoes, yellow corn meal, milk, vegetable oil\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'ingridients_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-4892c55ec4a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mingredients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ingredients'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_preprocessed_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_ingredients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cuisine'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mingredients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-189-63dedb79147b>\u001b[0m in \u001b[0;36mmake_preprocessed_matrix\u001b[1;34m(df, unique_ingridients)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m#ingridients_list = row[3].split(', ')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mingridient\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mingridients_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mingridient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mstemmed_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'ingridients_list' is not defined"
     ]
    }
   ],
   "source": [
    "a = train_df[0:2]\n",
    "#print a\n",
    "unique_ingredients = make_unique_ingredients_dict(a)\n",
    "#print unique_ingredients\n",
    "print train_df['ingredients'][0], train_df['ingredients'][1]\n",
    "ingredients = train_df['ingredients']\n",
    "\n",
    "X = make_preprocessed_matrix(train_df, unique_ingredients)\n",
    "y = train_df['cuisine']\n",
    "print len(y), X.shape, len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.617489236593 +/- 0.0109575034339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB(alpha = 0, fit_prior = False)\n",
    "estimate_acc(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-109-95ff17a93931>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-109-95ff17a93931>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    ingredients_test = test_df['ingredients'] for item in test_df]\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test_df = loadTestSet()\n",
    "\n",
    "ingredients_test = test_df['ingredients'] for item in test_df]\n",
    "X_test = dok_matrix((len(ingredients_test), len(unique_ingredients)), dtype=np.dtype(bool))\n",
    "\n",
    "for d,dish in enumerate(ingredients_test):\n",
    "    for i,ingredient in enumerate(unique_ingredients):\n",
    "        if ingredient in dish:\n",
    "            X_test[d,i] = True\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "cuisines_predicted = encoder.inverse_transform(y_predicted)\n",
    "result_dict = dict(zip(test_df['id'], cuisines_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
