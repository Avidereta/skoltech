{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model.base import BaseEstimator\n",
    "\n",
    "from utils import compute_labels, log_likelihood, log_likelihood_from_labels\n",
    "\n",
    "STOP_THRESHOLD = 0.01\n",
    "\n",
    "class Random(BaseEstimator):\n",
    "    def __init__(self, n_clusters, n_init=10):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_objects = X.shape[0]\n",
    "        best_log_likelihood = float(\"-inf\")\n",
    "        for i in range(self.n_init):\n",
    "            centers_idx = np.random.choice(n_objects, size=self.n_clusters, replace=False)\n",
    "            mu = X[centers_idx, :]\n",
    "            labels = compute_labels(X, mu)\n",
    "            ll = log_likelihood_from_labels(X, labels)\n",
    "            if ll > best_log_likelihood:\n",
    "                best_log_likelihood = ll\n",
    "                self.cluster_centers_ = mu.copy()\n",
    "                self.labels_ = labels\n",
    "                \n",
    "class EM(BaseEstimator):\n",
    "    def __init__(self, n_clusters, n_init=10):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        \n",
    "    def estep(self, X, w, mu, sigma):\n",
    "\n",
    "        \"\"\"Compute Gamma_ik.\n",
    "\n",
    "        X is n_objects x n_features matrix\n",
    "        w is a vector of size n_clusters of the prior probabilities of the clusters\n",
    "        mu is n_clusters x n_features matrix of the centers of the clusters\n",
    "        sigma is n_clusters x n_features x n_features tensor with the covariance\n",
    "                matrix of each cluster.\n",
    "        \"\"\"\n",
    "        assert_approx_equal(np.sum(w), 1)\n",
    "        n_objects, n_features = X.shape\n",
    "        n_clusters = w.size\n",
    "        log_gamma = np.zeros((n_objects, n_clusters))\n",
    "        for cluster in range(n_clusters):\n",
    "            log_gamma[:, cluster] = np.log(w[cluster])\n",
    "            log_gamma[:, cluster] += multivariate_normal.logpdf(X, np.exp(mu[cluster, :]),\n",
    "                                                                np.exp(sigma[cluster, :, :]))                                                            \n",
    "        norm_coef = logsumexp(log_gamma, axis=1)\n",
    "        for cluster in range(n_clusters):\n",
    "            log_gamma[:, cluster] -= norm_coef\n",
    "\n",
    "        return log_gamma\n",
    "    \n",
    "    def mstep(self, X, log_gamma):\n",
    "        mu = np.zeros((n_clusters, n_features))\n",
    "        sigma = np.zeros((n_clusters, n_features, n_features))\n",
    "        mu = np.exp(np.log(np.dot(np.exp(log_gamma).T, X))  \n",
    "                            - np.tile(logsumexp(log_gamma, axis=0), X.shape[1])) \n",
    "        \n",
    "        n_clusters = self.n_clusters\n",
    "        n_objects = X.shape[0]\n",
    "\n",
    "        for cluster in range(n_clusters):\n",
    "            gamma_k = np.exp(log_gamma[:, cluster])\n",
    "            mu_k = mu[cluster, :]\n",
    "            sigma[cluster, :, :] = np.exp(np.log(np.dot(np.tile(gamma_k, n_objects).T), \n",
    "                                        np.dot((X - np.tile(mu_k, n_objects)),(X - np.tile(mu_k, n_objects)).T))\n",
    "                                        - np.tile(logsumexp(log_gamma, axis=0), n_objects))\n",
    "        \n",
    "        w = logsumexp(log_gamma, axis=1)/n_objects \n",
    "        \n",
    "        return w, mu, sigma\n",
    "    \n",
    "    def fit(X):\n",
    "        \n",
    "        n_objects = X.shape[0]\n",
    "        \n",
    "        centers_idx = np.random.choice(n_objects, size=self.n_clusters, replace=False)\n",
    "        mu = X[centers_idx, :] \n",
    "        sigma = np.zeros((n_clusters, n_features, n_features))\n",
    "        w = np.tile(1.0/self.n_clusters, self.n_clusters)\n",
    "        \n",
    "        new_log_likelihood = log_likelihood(X, w, mu, sigma)\n",
    "        \n",
    "        for cluster in range (self.n_clusters):\n",
    "            sigma[cluster :, :] = np.dot(X - mu, (X - mu).T)\n",
    "\n",
    "        for i in range(self.n_init):\n",
    "            ll = log_likelihood(X, w, mu, sigma)\n",
    "            if abs(new_log_likelihood - ll) < STOP_THRESHOLD:\n",
    "                best_log_likelihood = ll\n",
    "                self.cluster_centers_ = mu.copy()\n",
    "                self.labels_ = compute_labels\n",
    "            else:\n",
    "                \n",
    "                log_gamma = self.estep(X,w, mu, sigma)\n",
    "                mu, sigma = self.mstep(log_gamma)\n",
    "                new_log_likelihood = ll\n",
    "                i+=1\n",
    "                if i == self.n_init:\n",
    "                    print 'There is no convergence'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = \n",
    "print x\n",
    "print (np.tile(x, (2,1))).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
